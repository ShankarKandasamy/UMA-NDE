{
  "page_number": "1",
  "analysis": {
    "total_buckets": 19,
    "filtered_buckets": [
      {
        "bucket_id": 17,
        "text": "1",
        "reason": "too_short"
      }
    ],
    "matched_buckets": [
      {
        "bucket_id": 0,
        "text": "DeepWalk: Online Learning\"  of Social Representations",
        "confidence": 1.0,
        "method": "exact_match"
      },
      {
        "bucket_id": 1,
        "text": "Bryan Perozzi Stony Brook University Department of Computer Science",
        "confidence": 1.0,
        "method": "exact_match"
      },
      {
        "bucket_id": 2,
        "text": "Rami AI- Rfou Stony Brook Iniversity Department of Computer Scienc e",
        "confidence": 0.9552238805970148,
        "method": "fuzzy_match"
      },
      {
        "bucket_id": 3,
        "text": "Steven Skiena Stony Brook University Department of Computer Science",
        "confidence": 1.0,
        "method": "exact_match"
      },
      {
        "bucket_id": 4,
        "text": "{bperozzi, ralrfou; skien a}@cs.stonybrook edu",
        "confidence": 0.9761904761904762,
        "method": "fuzzy_match"
      },
      {
        "bucket_id": 5,
        "text": "ABSTRACT",
        "confidence": 1.0,
        "method": "exact_match"
      },
      {
        "bucket_id": 6,
        "text": "We present DEEPWALK, novel approach for learning la- a tent representations of vertices in network. a These latent 3 representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DEEP - WALK   generalizes  recent advancements in language  mod- eling and unsupervised feature learning (Or deep learning ) 4 from sequences of words to graphs: DEEPWALK uses local information obtained from trun- cated random walks to learn latent representations by treat- ing walks as the equivalent of sentences We demonstrate DEEP WALK's latent representations on several  multi-label network classification tasks for social networks such as Blog- 5 Catalog; Flickr, and YouTube: Our results show that DEEP - WALK outperforms challenging baselines which are allowed a global view of the network; especially in the presence of missing information: DEEP WALK's representations can pro Itido 1 UL when labeled data is sparse. In some experiments, DEEP - WALK's representations are able to outperform all baseline 100 kicbor fban comnotinc motbede 10 / U",
        "confidence": 0.947069943289225,
        "method": "fuzzy_match"
      },
      {
        "bucket_id": 7,
        "text": "up 3 methods while using 60% less training data. Categories and Subject Descriptors H.2.8 [Database Management]: Database   Applications Data Mining; 1.2.6 [Artificial Intelligence]: Learning; I.5.1 [Pattern Recognition]: Model Statistical 1. INTRODUCTION The sparsity of a network representation is both a strength and weakness   Sparsity enables the design of efficient dis- a crete algorithms; but can make it harder to generalize in statistical learning: Machine learning   applications in net- works (such as network classification [15,37], content rec -",
        "confidence": 0.9829867674858223,
        "method": "fuzzy_match"
      },
      {
        "bucket_id": 9,
        "text": "0.6 -0.8 -1.0 -1.2 -1.4 -1.6 -1.8 -1.0 -0.5 0.0",
        "confidence": 0.7142857142857143,
        "method": "word_coverage"
      },
      {
        "bucket_id": 10,
        "text": "(b) Output: Representation",
        "confidence": 0.8421052631578947,
        "method": "ngram_overlap"
      },
      {
        "bucket_id": 11,
        "text": "1.5 2.0 2.5",
        "confidence": 0.75,
        "method": "word_coverage"
      },
      {
        "bucket_id": 13,
        "text": "(a) Input: Karate Graph",
        "confidence": 1.0,
        "method": "word_coverage"
      },
      {
        "bucket_id": 14,
        "text": "Figure l: Our proposed method learns a latent space rep- resentation of social interactions in Rd The learned rep- resentation encodes community structure s0 it can be eas- ily exploited by standard classification methods: Here, our method is used on Zachary's Karate network [44] to gen- erate latent   representation a in R2 _ Note the correspon- dence between community structure in the input graph and the embedding: Vertex colors represent a modularity-based",
        "confidence": 0.9754464285714286,
        "method": "fuzzy_match"
      },
      {
        "bucket_id": 16,
        "text": "ommendation [11], anomaly detection [5], and missing link prediction [22]) must be able to deal with this sparsity in order to survive. In this paper we introduce deep learning  (unsupervised feature learning) [2] techniques, which have proven success- ful in natural language processing; into network analysis for the first time. We develop an algorithm (DEEPWALK) that learns social representations of a graph' < s vertices, by mod- eling a stream of short random walks. Social representa- tions are latent features of the vertices that capture neigh- borhood similarity and community membership. These la- tent representations encode social relations in a continuous vector space with a relatively small number of dimensions. DEEPWALK generalizes neural language models to process a special language composed of a set of randomly-generated walks. These neural language  models have been used to capture the semantic and syntactic structure of human lan- guage [6], and even logical analogies [28]. DEEPWALK takes a graph as input and produces la- a tent representation as an output. The result of applying our method to the well-studied Karate network is shown in Fig- ure 1. The graph, as typically presented by force-directed layouts, is shown in Figure la. Figure lb shows the output of our method with 2 latent dimensions. Beyond the striking similarity, we note that linearly separable portions of (1b) correspond to clusters found through modularity maximiza- tion in the input graph (1a) (shown as vertex colors) To demonstrate DEEPWALK's potential in real world sce-",
        "confidence": 0.9684002633311389,
        "method": "fuzzy_match"
      }
    ],
    "missing_buckets": [
      {
        "bucket_id": 8,
        "text": "DEEPWALK is also scalable. It is an online learning algo- rithm which builds useful incremental results; and is trivially parallelizable. These qualities make it suitable for broad a class  of real world applications such as network classifica- tion, and anomaly detection:",
        "texts": [
          "DEEPWALK is also scalable. It is an online learning algo-",
          "rithm which builds useful incremental results; and is trivially",
          "parallelizable. These qualities make it suitable for broad a",
          "class  of real world applications such as network classifica-",
          "tion, and anomaly detection:"
        ],
        "position": "left",
        "width_category": "medium",
        "y_group_id": 5,
        "confidence_avg": 0.95,
        "char_count": 269,
        "word_count": 41,
        "confidence_missing": 0.47547169811320755,
        "method_tried": "missing"
      },
      {
        "bucket_id": 12,
        "text": "0.5 1.0",
        "texts": [
          "0.5",
          "1.0"
        ],
        "position": "right",
        "width_category": "narrow",
        "y_group_id": 4,
        "confidence_avg": 1.0,
        "char_count": 6,
        "word_count": 2,
        "confidence_missing": 0.2857142857142857,
        "method_tried": "missing"
      },
      {
        "bucket_id": 15,
        "text": "OU1 UIIC",
        "texts": [
          "OU1 UIIC"
        ],
        "position": "center",
        "width_category": "narrow",
        "y_group_id": 5,
        "confidence_avg": 0.39,
        "char_count": 8,
        "word_count": 2,
        "confidence_missing": 0.5,
        "method_tried": "missing"
      },
      {
        "bucket_id": 18,
        "text": "The authors, 2014. This is the author $ draft of the work: It is posted here for your personal use. Not for redistribution: The definitive version was published in KDD' 14, http: / /dx.doi.org/10.1145/2623330 _ 2623732",
        "texts": [
          "The authors, 2014. This is the author $ draft of the work: It is posted here",
          "for your personal use. Not for redistribution: The definitive version was",
          "published in KDD' 14, http: / /dx.doi.org/10.1145/2623330 _",
          "2623732"
        ],
        "position": "left",
        "width_category": "medium",
        "y_group_id": 7,
        "confidence_avg": 0.7,
        "char_count": 215,
        "word_count": 36,
        "confidence_missing": 0.5714285714285714,
        "method_tried": "missing"
      }
    ],
    "llm_reported_missing": []
  },
  "recovery": {
    "markdown": "# DeepWalk: Online Learning of Social Representations\n\nBryan Perozzi  \nStony Brook University  \nDepartment of Computer Science  \n\nRami Al-Rfou  \nStony Brook University  \nDepartment of Computer Science  \n\nSteven Skiena  \nStony Brook University  \nDepartment of Computer Science  \n\n{bperozzi, ralrfou, skiena}@cs.stonybrook.edu  \n\n## ABSTRACT\nWe present DEEPWALK, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DEEPWALK generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs: DEEPWALK uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DEEPWALK's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DEEPWALK outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DEEPWALK's representations can provide significant improvements when labeled data is sparse. In some experiments, DEEPWALK's representations are able to outperform all baseline methods while using 60% less training data.\n\nDEEPWALK is also scalable. It is an online learning algorithm which builds useful incremental results; and is trivially parallelizable. These qualities make it suitable for broad a class of real world applications such as network classification, and anomaly detection:\n\n## Categories and Subject Descriptors\nH.2.8 [Database Management]: Database Applications; Data Mining; I.2.6 [Artificial Intelligence]: Learning; I.5.1 [Pattern Recognition]: Model - Statistical\n\n## 1. INTRODUCTION\nThe sparsity of a network representation is both a strength and a weakness. Sparsity enables the design of efficient discrete algorithms, but can make it harder to generalize in statistical learning. Machine learning applications in networks (such as network classification [15,37], content recommendation [11], anomaly detection [5], and missing link prediction [22]) must be able to deal with this sparsity in order to survive.\n\nIn this paper we introduce deep learning (unsupervised feature learning) techniques, which have proven successful in natural language processing, into network analysis for the first time. We develop an algorithm (DEEPWALK) that learns social representations of a graph's vertices by modeling a stream of short random walks. Social representations are latent features of the vertices that capture neighborhood similarity and community membership. These latent representations encode social relations in a continuous vector space with a relatively small number of dimensions. DEEPWALK generalizes neural language models to process a special language composed of a set of randomly-generated walks. These neural language models have been used to capture the semantic and syntactic structure of human language and even logical analogies.\n\nDEEPWALK takes a graph as input and produces a latent representation as an output. The result of applying our method to the well-studied Karate network is shown in Figure 1. The graph, as typically presented by force-directed layouts, is shown in Figure 1a. Figure 1b shows the output of our method with 2 latent dimensions. Beyond the striking similarity, we note that linearly separable portions of (1b) correspond to clusters found through modularity maximization in the input graph (1a) (shown as vertex colors).\n\n> Figure 1: Our proposed method learns a latent space representation of social interactions in R². The learned representation encodes community structure so it can be easily exploited by standard classification methods. Here, our method is used on Zachary's Karate network [44] to generate a latent representation in R². Note the correspondence between community structure in the input graph and the embedding: Vertex colors represent a modularity-based clustering of the input graph.\n\n0.5\n1.0\n\nThe authors, 2014. This is the author's draft of the work: It is posted here for your personal use. Not for redistribution: The definitive version was published in KDD' 14, http://dx.doi.org/10.1145/2623330_2623732",
    "buckets_recovered": [
      8,
      12,
      18
    ],
    "buckets_gibberish": [
      15
    ],
    "recovery_notes": "Inserted legitimate text from buckets 8, 12, and 18 into the appropriate sections of the markdown. Bucket 15 was identified as gibberish and not included."
  }
}